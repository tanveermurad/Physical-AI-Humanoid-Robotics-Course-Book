<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-part2-ai-for-robotics/learning" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Machine Learning for Robotics | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://tanveermurad.github.io/Physical-AI-Humanoid-Robotics-Course-Book/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://tanveermurad.github.io/Physical-AI-Humanoid-Robotics-Course-Book/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://tanveermurad.github.io/Physical-AI-Humanoid-Robotics-Course-Book/docs/part2-ai-for-robotics/learning"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Machine Learning for Robotics | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="While traditional methods in robotics rely on precise models and explicit programming, machine learning offers a powerful alternative: enabling robots to learn from data and experience. Learning allows robots to operate in unstructured environments, adapt to new situations, and acquire complex skills that would be difficult or impossible to program by hand."><meta data-rh="true" property="og:description" content="While traditional methods in robotics rely on precise models and explicit programming, machine learning offers a powerful alternative: enabling robots to learn from data and experience. Learning allows robots to operate in unstructured environments, adapt to new situations, and acquire complex skills that would be difficult or impossible to program by hand."><link data-rh="true" rel="icon" href="/Physical-AI-Humanoid-Robotics-Course-Book/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://tanveermurad.github.io/Physical-AI-Humanoid-Robotics-Course-Book/docs/part2-ai-for-robotics/learning"><link data-rh="true" rel="alternate" href="https://tanveermurad.github.io/Physical-AI-Humanoid-Robotics-Course-Book/docs/part2-ai-for-robotics/learning" hreflang="en"><link data-rh="true" rel="alternate" href="https://tanveermurad.github.io/Physical-AI-Humanoid-Robotics-Course-Book/docs/part2-ai-for-robotics/learning" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Machine Learning for Robotics","item":"https://tanveermurad.github.io/Physical-AI-Humanoid-Robotics-Course-Book/docs/part2-ai-for-robotics/learning"}]}</script><link rel="alternate" type="application/rss+xml" href="/Physical-AI-Humanoid-Robotics-Course-Book/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/Physical-AI-Humanoid-Robotics-Course-Book/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0BTd_VIRyD2IhJUr3BuVJHGb5A4UqpghpscqimF1/+bM2SXpyVGa7A+3S+4" crossorigin="anonymous"><link rel="stylesheet" href="/Physical-AI-Humanoid-Robotics-Course-Book/assets/css/styles.9c53a5ce.css">
<script src="/Physical-AI-Humanoid-Robotics-Course-Book/assets/js/runtime~main.0ae6ebcf.js" defer="defer"></script>
<script src="/Physical-AI-Humanoid-Robotics-Course-Book/assets/js/main.1d8b1ce6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/Physical-AI-Humanoid-Robotics-Course-Book/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Physical-AI-Humanoid-Robotics-Course-Book/"><div class="navbar__logo"><img src="/Physical-AI-Humanoid-Robotics-Course-Book/img/logo.svg" alt="Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Physical-AI-Humanoid-Robotics-Course-Book/img/logo.svg" alt="Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/intro">Book</a><a class="navbar__item navbar__link" href="/Physical-AI-Humanoid-Robotics-Course-Book/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/tanveermurad/Physical-AI-Humanoid-Robotics-Course-Book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/intro"><span title="Introduction to Physical AI and Humanoid Robotics" class="linkLabel_WmDU">Introduction to Physical AI and Humanoid Robotics</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/part1-fundamentals-of-robotics/kinematics"><span title="Part 1: Fundamentals of Robotics" class="categoryLinkLabel_W154">Part 1: Fundamentals of Robotics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/part2-ai-for-robotics/planning"><span title="Part 2: AI for Robotics" class="categoryLinkLabel_W154">Part 2: AI for Robotics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/part2-ai-for-robotics/planning"><span title="Planning" class="linkLabel_WmDU">Planning</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/part2-ai-for-robotics/perception"><span title="Perception" class="linkLabel_WmDU">Perception</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/part2-ai-for-robotics/learning"><span title="Machine Learning for Robotics" class="linkLabel_WmDU">Machine Learning for Robotics</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/part3-humanoid-robotics/bipedal-locomotion"><span title="Part 3: Humanoid Robotics" class="categoryLinkLabel_W154">Part 3: Humanoid Robotics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/tutorial-basics/create-a-blog-post"><span title="Tutorial Basics" class="categoryLinkLabel_W154">Tutorial Basics</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Physical-AI-Humanoid-Robotics-Course-Book/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Part 2: AI for Robotics</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Machine Learning for Robotics</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Machine Learning for Robotics</h1></header>
<p>While traditional methods in robotics rely on precise models and explicit programming, machine learning offers a powerful alternative: enabling robots to <strong>learn</strong> from data and experience. Learning allows robots to operate in unstructured environments, adapt to new situations, and acquire complex skills that would be difficult or impossible to program by hand.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="supervised-learning">Supervised Learning<a href="#supervised-learning" class="hash-link" aria-label="Direct link to Supervised Learning" title="Direct link to Supervised Learning" translate="no">​</a></h2>
<p>Supervised learning is the most common form of machine learning. It involves training a model on a labeled dataset, where each data point has a corresponding &quot;correct&quot; output. The model learns to map inputs to outputs.</p>
<p>In robotics, supervised learning is the powerhouse behind most perception systems:</p>
<ul>
<li class=""><strong>Object Recognition</strong>: A model is trained on thousands of images labeled with object classes (&quot;cat,&quot; &quot;car,&quot; &quot;person&quot;). The trained model can then recognize these objects in new images.</li>
<li class=""><strong>Semantic Segmentation</strong>: A model is trained on images where every pixel is labeled with its category (&quot;road,&quot; &quot;sky,&quot; &quot;building&quot;).</li>
</ul>
<p>The main challenge for supervised learning in robotics is the need for large, labeled datasets, which can be expensive and time-consuming to create.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="reinforcement-learning-rl">Reinforcement Learning (RL)<a href="#reinforcement-learning-rl" class="hash-link" aria-label="Direct link to Reinforcement Learning (RL)" title="Direct link to Reinforcement Learning (RL)" translate="no">​</a></h2>
<p>Reinforcement learning is about learning from trial and error. An <strong>agent</strong> (the robot) interacts with an <strong>environment</strong> and receives a <strong>reward</strong> signal for its actions. The goal of the agent is to learn a <strong>policy</strong>—a mapping from states to actions—that maximizes its cumulative reward over time.</p>
<p><img decoding="async" loading="lazy" src="https://i.imgur.com/32sO3y9.png" alt="Reinforcement Learning Diagram" class="img_ev3q"></p>
<p>RL is a natural fit for many robotics problems:</p>
<ul>
<li class=""><strong>Locomotion</strong>: A robot can learn to walk, run, or fly by being rewarded for moving forward without falling.</li>
<li class=""><strong>Manipulation</strong>: A robot can learn to grasp objects or assemble parts by being rewarded for successfully completing the task.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="challenges-in-rl-for-robotics">Challenges in RL for Robotics<a href="#challenges-in-rl-for-robotics" class="hash-link" aria-label="Direct link to Challenges in RL for Robotics" title="Direct link to Challenges in RL for Robotics" translate="no">​</a></h3>
<ul>
<li class=""><strong>Sample Inefficiency</strong>: RL often requires millions of trials to learn a good policy, which is often not feasible on a physical robot.</li>
<li class=""><strong>Reward Shaping</strong>: Designing a good reward function can be difficult. A sparse reward (e.g., +1 only when the entire task is complete) can make learning very slow.</li>
<li class=""><strong>Safety</strong>: The robot may perform dangerous actions during the exploration phase.</li>
</ul>
<p><strong>Sim-to-Real Transfer</strong>: A common strategy to overcome these challenges is to train the policy in a simulator and then transfer it to the real robot. This requires a high-fidelity simulator and techniques to bridge the &quot;reality gap&quot; between the simulation and the real world.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="imitation-learning">Imitation Learning<a href="#imitation-learning" class="hash-link" aria-label="Direct link to Imitation Learning" title="Direct link to Imitation Learning" translate="no">​</a></h2>
<p>A major bottleneck in RL is the need to design a reward function. Imitation learning (also known as Learning from Demonstration) provides a more intuitive way to teach a robot a skill: by showing it what to do.</p>
<ul>
<li class=""><strong>Behavioral Cloning (BC)</strong>: This is the simplest form of imitation learning. A supervised learning model is trained to directly map the states observed by an expert to the actions the expert took. It&#x27;s like a student mimicking a teacher&#x27;s every move. BC is simple but can fail if the robot encounters a state that was not in the expert&#x27;s demonstrations.</li>
<li class=""><strong>Inverse Reinforcement Learning (IRL)</strong>: Instead of trying to learn the expert&#x27;s policy directly, IRL tries to learn the expert&#x27;s underlying <strong>reward function</strong>. Once the reward function is learned, it can be used to train a policy using standard RL methods. This often leads to more robust policies than behavioral cloning.</li>
</ul>
<p>Machine learning is a rapidly evolving field that is fundamentally changing how we design and program robots. By combining the principles of classical robotics with the power of data-driven learning, we can create robots that are more intelligent, adaptable, and capable than ever before.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/tanveermurad/Physical-AI-Humanoid-Robotics-Course-Book/tree/main/my-book/docs/part2-ai-for-robotics/learning.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/part2-ai-for-robotics/perception"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Perception</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/part3-humanoid-robotics/bipedal-locomotion"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Bipedal Locomotion</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#supervised-learning" class="table-of-contents__link toc-highlight">Supervised Learning</a></li><li><a href="#reinforcement-learning-rl" class="table-of-contents__link toc-highlight">Reinforcement Learning (RL)</a><ul><li><a href="#challenges-in-rl-for-robotics" class="table-of-contents__link toc-highlight">Challenges in RL for Robotics</a></li></ul></li><li><a href="#imitation-learning" class="table-of-contents__link toc-highlight">Imitation Learning</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Book</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Physical-AI-Humanoid-Robotics-Course-Book/docs/intro">Introduction</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Physical-AI-Humanoid-Robotics-Course-Book/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/tanveermurad/Physical-AI-Humanoid-Robotics-Course-Book" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>